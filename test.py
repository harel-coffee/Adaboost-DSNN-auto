# -*- coding: utf-8 -*-
"""Untitled42.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LiHw1gbJop7__6bvFR89N5brdYRJiOGA
"""

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, AlphaDropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import backend as K
import numpy as np
import time


batch_size = 128
num_classes = 10
epochs = 20

# input image dimensions
img_rows, img_cols = 28, 28

# list devices so you can check whether your gpu is available
print(tf.config.list_physical_devices())

# the data, shuffled and split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

if K.image_data_format() == 'channels_first':
    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
    input_shape = (1, img_rows, img_cols)
else:
    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
    input_shape = (img_rows, img_cols, 1)

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
#x_train = (x_train - np.mean(x_train))/np.std(x_train)

x_test /= 255
#x_test = (x_test - np.mean(x_train))/np.std(x_train)

# create validation file
x_val = x_train[:10000]
x_train = x_train[10000:]
y_val = y_train[:10000]
y_train = y_train[10000:]

print('x_train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')
print(x_val.shape[0], 'val samples')
print(x_test.shape[0], 'test samples')

# convert class vectors to binary class matrices
y_train = keras.utils.to_categorical(y_train, num_classes)
y_val = keras.utils.to_categorical(y_val, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

start_time=time.time()
def new_DSNN():
  model = Sequential()
  model.add(Flatten())
  model.add(Dense(512, activation='selu',kernel_initializer='lecun_normal',bias_initializer='zeros'))
  model.add(AlphaDropout(0.05))
  model.add(Dense(256, activation='selu',kernel_initializer='lecun_normal',bias_initializer='zeros'))
  model.add(AlphaDropout(0.05))
  model.add(Dense(num_classes, activation='softmax',kernel_initializer='lecun_normal',bias_initializer='zeros'))

  model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=keras.optimizers.Adam(learning_rate=0.001),
              metrics=['accuracy'])
  return model

model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=epochs,
          verbose=1,
          validation_data=(x_val, y_val))
print(".....%s seconds.."% (time.time ()-start_time))

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

from SNNadaboost import AdaBoostClassifier as Ada_NN
n_estimators =10
epochs =100
bdt_real_test_NN = Ada_NN(
    base_estimator=new_DSNN,
    n_estimators=n_estimators,
    learning_rate=0.001,
    epochs=epochs)
#######discreat:

bdt_real_test_NN.fit(x_train, y_train, batch_size)
test_real_errors_NN=bdt_real_test_NN.estimator_errors_[:]



y_pred_NN = bdt_real_test_NN.predict(X_train_r)
print('\n Training accuracy of bdt_real_test_CNN (AdaBoost+CNN): {}'.format(accuracy_score(bdt_real_test_NN.predict(X_train_r),y_train)))

y_pred_NN = bdt_real_test_NN.predict(X_test_r)
print('\n Testing accuracy of bdt_real_test_CNN (AdaBoost+CNN): {}'.format(accuracy_score(bdt_real_test_CNN.predict(X_test_r),y_test)))